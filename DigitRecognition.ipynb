{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mridul60/Machine-Learnings-Curriculum/blob/main/DigitRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "426ce1dc-baca-4dd5-b4d7-dcdec856a606",
      "metadata": {
        "id": "426ce1dc-baca-4dd5-b4d7-dcdec856a606"
      },
      "source": [
        "### ***Assignment 1:*** Recognize a Digit using TensorFlow / PyTorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2665e0a7-ee4c-4aa1-b195-bf57bc4612ee",
      "metadata": {
        "id": "2665e0a7-ee4c-4aa1-b195-bf57bc4612ee"
      },
      "source": [
        "# Step 0: Install required packages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b986910-6170-4964-b66b-483c8cbd2631",
      "metadata": {
        "id": "3b986910-6170-4964-b66b-483c8cbd2631"
      },
      "source": [
        "# Step 1: Import Required Libraries\n",
        "We first import the libraries we need for:\n",
        "- **TensorFlow** → Deep learning framework to build and train our model.\n",
        "- **NumPy** → To handle numeric arrays.\n",
        "- **Matplotlib** → To visualize images and results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "03373099-eb15-496a-a5b3-0e0d121616e8",
      "metadata": {
        "id": "03373099-eb15-496a-a5b3-0e0d121616e8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de9f2e22-4a8a-44ce-a923-4974315d0f1e",
      "metadata": {
        "id": "de9f2e22-4a8a-44ce-a923-4974315d0f1e"
      },
      "source": [
        "# Step 2: Load the MNIST Dataset\n",
        "- The MNIST dataset contains **70,000 images** of handwritten digits (0–9).\n",
        "- It’s already included inside TensorFlow for quick access.\n",
        "- `x_train`, `y_train` → 60,000 training samples and labels.\n",
        "- `x_test`, `y_test` → 10,000 test samples and labels.\n",
        "- Each image is **28×28 pixels**, grayscale.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e6e0e580-4e71-4fb4-afac-18f52db830bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6e0e580-4e71-4fb4-afac-18f52db830bd",
        "outputId": "1bb66d05-273c-46ec-dabb-2d61dc82ba70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ea57e40-f341-498a-b254-6a3aded6a7e3",
      "metadata": {
        "id": "0ea57e40-f341-498a-b254-6a3aded6a7e3"
      },
      "source": [
        "# Step 3: Normalize and Reshape the Data\n",
        "1. **Normalization**: Convert pixel values from [0, 255] → [0, 1] for faster training.\n",
        "2. **Reshape**: Add a channel dimension (1 for grayscale images) so that\n",
        "   the data fits the CNN input format `(height, width, channels)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4fcb5f06-e158-4941-a473-df3209a82055",
      "metadata": {
        "id": "4fcb5f06-e158-4941-a473-df3209a82055"
      },
      "outputs": [],
      "source": [
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "381e337f-8f41-401f-9893-7961ee5bbd52",
      "metadata": {
        "id": "381e337f-8f41-401f-9893-7961ee5bbd52"
      },
      "source": [
        "# Step 4: Build the CNN Model\n",
        "We use a **Sequential model** which stacks layers in order:\n",
        "\n",
        "1. **Conv2D(32, (3×3), relu)** → Extracts 32 feature maps using 3×3 filters.\n",
        "2. **MaxPooling2D(2×2)** → Reduces the size of feature maps by taking the max in each 2×2 window.\n",
        "3. **Flatten()** → Converts 2D feature maps into a 1D vector.\n",
        "4. **Dense(64, relu)** → Fully connected layer with 64 neurons for learning patterns.\n",
        "5. **Dense(10, softmax)** → Output layer for 10 digit classes with probability distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "29a27e26-0f6c-429d-ad02-58cd2d62054c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29a27e26-0f6c-429d-ad02-58cd2d62054c",
        "outputId": "4ef4702d-c951-42fb-c05c-604bbf577a09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71cd36ba-37dd-4e59-bd0e-e0ab04d0ba17",
      "metadata": {
        "id": "71cd36ba-37dd-4e59-bd0e-e0ab04d0ba17"
      },
      "source": [
        "# Step 5: Compile the Model\n",
        "- **Optimizer**: Adam (adaptive learning rate optimization).\n",
        "- **Loss Function**: Sparse Categorical Crossentropy (good for integer labels).\n",
        "- **Metrics**: Accuracy to track model performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f5b5866c-e480-4c17-ba5c-fffdfc80562d",
      "metadata": {
        "id": "f5b5866c-e480-4c17-ba5c-fffdfc80562d"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9522b3fa-cc01-4934-b297-81b50c4901c8",
      "metadata": {
        "id": "9522b3fa-cc01-4934-b297-81b50c4901c8"
      },
      "source": [
        "# Step 6: Train the Model\n",
        "- Train for 5 epochs (full passes over the training set).\n",
        "- The model adjusts weights each epoch to minimize loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5e0b04be-6c56-4206-b84d-ebed0289c7c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e0b04be-6c56-4206-b84d-ebed0289c7c7",
        "outputId": "0ae316db-97a3-4428-b1fc-5e43b473abf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8955 - loss: 0.3410\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.9806 - loss: 0.0641\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9874 - loss: 0.0421\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9916 - loss: 0.0278\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.9935 - loss: 0.0194\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fddcd271f90>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1f97243-1c25-49f8-a5a6-9db763ea6045",
      "metadata": {
        "id": "e1f97243-1c25-49f8-a5a6-9db763ea6045"
      },
      "source": [
        "# Step 7: Evaluate on Test Data\n",
        "- We check how well the trained model performs on unseen test data.\n",
        "- Outputs: Test loss and accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "976f4e2b-f79e-427e-825a-d2d2b97bbd8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "976f4e2b-f79e-427e-825a-d2d2b97bbd8d",
        "outputId": "34268f02-1e6e-4ab0-ae79-4a01f706dff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9811 - loss: 0.0547\n",
            "Test accuracy: 0.9857\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23b6ff02-2926-4874-a845-3281c2335f9b",
      "metadata": {
        "id": "23b6ff02-2926-4874-a845-3281c2335f9b"
      },
      "source": [
        "# Step 8: Make a Prediction\n",
        "- Randomly pick one image from the test set.\n",
        "- Use `model.predict()` to guess its label.\n",
        "- Use `np.argmax()` to find the class with the highest probability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0fb9fada-cf20-4f66-bd4c-a3ff9ecf3089",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fb9fada-cf20-4f66-bd4c-a3ff9ecf3089",
        "outputId": "76ee8b91-e6c5-42a1-a46a-1617a6e2baf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n"
          ]
        }
      ],
      "source": [
        "index = np.random.randint(0, len(x_test))\n",
        "sample_image = x_test[index]\n",
        "true_label = y_test[index]\n",
        "\n",
        "prediction = model.predict(sample_image.reshape(1, 28, 28, 1))\n",
        "predicted_label = np.argmax(prediction)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbf04a41-edc8-4954-b22b-a43f222189f5",
      "metadata": {
        "id": "bbf04a41-edc8-4954-b22b-a43f222189f5"
      },
      "source": [
        "# Step 9: Display the Prediction\n",
        "- Show the chosen test image.\n",
        "- Title includes both the true label and predicted label.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5aabc2dc-cbe1-40cb-9c6e-c3a8010de944",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "5aabc2dc-cbe1-40cb-9c6e-c3a8010de944",
        "outputId": "76c11638-8914-4d6d-8011-6d3dc34c23a1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(sample_image.squeeze(), cmap='gray')\n",
        "plt.title(f\"True: {true_label}, Predicted: {predicted_label}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f31731a0-ebc0-49c6-8a50-9bc3cb7ec686",
      "metadata": {
        "id": "f31731a0-ebc0-49c6-8a50-9bc3cb7ec686"
      },
      "source": [
        "# Step 10: Save the Model\n",
        "We save the trained model as `digit_model.keras` so it can be reused later\n",
        "without retraining (for example, in a Streamlit app).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8e766890-6f31-44a3-9883-d82f2afd40a9",
      "metadata": {
        "id": "8e766890-6f31-44a3-9883-d82f2afd40a9"
      },
      "outputs": [],
      "source": [
        "model.save('digit_model.keras')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "MachineLearning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}